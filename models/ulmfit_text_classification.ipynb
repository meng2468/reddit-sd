{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ulmfit_text_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4foQ9X5kA2FZ"
      },
      "source": [
        "References:\n",
        "\n",
        "\n",
        "1.   https://course19.fast.ai/videos/?lesson=12\n",
        "2.   https://www.analyticsvidhya.com/blog/2018/11/tutorial-text-classification-ulmfit-fastai-library/?utm_source=blog&utm_medium=top-pretrained-models-nlp-article\n",
        "3.   https://forums.fast.ai/t/how-to-load-pre-trained-model-wt103-from-local-directory/52585\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLEeSdhRj9Rf"
      },
      "source": [
        "!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyZXFu2gkJua"
      },
      "source": [
        "!pip install fastai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC8e1iDdkP0w"
      },
      "source": [
        "#import libraries\n",
        "import fastai\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import io\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI1pUjv_k5VN",
        "outputId": "63cdbee0-73f9-4ee9-bc4c-cb6bbcc41e90"
      },
      "source": [
        "#import dataset\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
        "documents = dataset.data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XX8gi3UlYUL"
      },
      "source": [
        "#create dataframe\n",
        "df = pd.DataFrame({'label': dataset.target, 'text': dataset.data})"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4aV9qw3ll-B",
        "outputId": "298d1d84-e40a-4d1a-da8c-c06f38ae06d7"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r67566iloAO"
      },
      "source": [
        "'''\n",
        "binary classification problem\n",
        "select labels 1 and 10 which correspond to ‘comp.graphics’ and ‘rec.sport.hockey’, respectively\n",
        "'''\n",
        "df = df[df['label'].isin([1,10])]\n",
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIVzzMEHl5Qt",
        "outputId": "6a1e648f-2d61-4dae-e4c2-1d2d4fe7df39"
      },
      "source": [
        "#check evenness of data points \n",
        "df['label'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10    600\n",
              "1     584\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY31hOupmdCV"
      },
      "source": [
        "PREPROCESS THE TEXT(we can do with spacy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fk3wVwVm6lz"
      },
      "source": [
        "#tokenization\n",
        "tokenized_doc = df['text'].apply(lambda x: x.split())\n",
        "\n",
        "# de-tokenization\n",
        "detokenized_doc = []\n",
        "for i in range(len(df)):\n",
        "  t = ' '.join(tokenized_doc[i])\n",
        "  detokenized_doc.append(t)\n",
        "\n",
        "df['text'] = detokenized_doc"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehU7NhXSnrfT"
      },
      "source": [
        "#split to train test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#split data into training and validation sets\n",
        "df_trn, df_val = train_test_split(df, stratify = df['label'], test_size = 0.4, random_state = 12)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSi4D-16ooA5",
        "outputId": "4eb2cee3-df00-4ce6-d48c-137fe13b798c"
      },
      "source": [
        "df_trn.shape, df_val.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((710, 2), (474, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "98llphDMorYC",
        "outputId": "484a10b7-a2a4-43e4-8a3a-b9ba60f28345"
      },
      "source": [
        "#Prepares language model data\n",
        "data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = \"\")\n",
        "\n",
        "#Prepares classifier model data\n",
        "data_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn, valid_df = df_val, vocab = data_lm.train_ds.vocab, bs=32)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFyE-ZNPsdA9"
      },
      "source": [
        "PRETRAINING AND FINE TUNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ifXZlZTSpnd-",
        "outputId": "73981295-6775-4729-d06f-334df789ad7f"
      },
      "source": [
        "#get pretrained language model\n",
        "learn = language_model_learner(data_lm, arch=AWD_LSTM, pretrained=True, drop_mult=0.7)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "id": "ehOdL-DMs6cW",
        "outputId": "081f77b0-90dd-4a40-ad57-9daf874da17c"
      },
      "source": [
        "# train the learner object with learning rate = 1e-2, cyclic momentum https://arxiv.org/abs/1803.09820\n",
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.587978</td>\n",
              "      <td>4.003945</td>\n",
              "      <td>0.279759</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbGOz1JVs68N"
      },
      "source": [
        "#save model to use for classification later\n",
        "learn.save_encoder('ft_enc')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQaO7PIIvDiW",
        "outputId": "ade4105d-3c74-40bf-d7fa-b3491c24bbe4"
      },
      "source": [
        "#use the data for classification\n",
        "learn = text_classifier_learner(data_clas, arch=AWD_LSTM, drop_mult=0.7)\n",
        "#load previously saved model\n",
        "learn.load_encoder('ft_enc')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (710 items)\n",
              "x: TextList\n",
              "xxbos xxrep 8 . xxmaj it looks like the xxmaj edmonton xxmaj oilers just decided to take a xxmaj european xxunk this spring ... xxmaj ranford , xxmaj tugnutt , xxmaj benning , xxmaj manson , xxmaj smith , xxmaj buchberger , and xxmaj corson are playing for xxmaj canada . xxmaj podein and xxmaj weight are playing for the xxup us . xxmaj is xxmaj kravchuk playing for the xxmaj xxunk ... i know he had nagging injuries late in the season . xxmaj podein is an interesting case ... because he was eligible to play in xxmaj cape xxmaj breton in the xxup ahl playoffs like xxmaj kovalev , xxmaj zubov , and xxmaj andersson ... obviously xxmaj sather and xxmaj pocklington are not the total xxunk everyone makes them out to be ... certainly in this case they 've massively xxunk xxmaj paramount and the xxmaj new xxmaj york xxmaj rangers .,xxbos * xxmaj this is what xxunk me : xxrep 79 * xxmaj speaking of \" die hard \" , that 's what i did when i read this , xxunk hard xxunk ! xxmaj toronto , to the xxmaj cup finals ? ? ? xxmaj first of all , has anyone on the planet heard of the team from xxmaj detroit ? xxmaj al xxmaj xxunk ( or however you spell the idiot 's name ) must be from xxmaj chicago , because on xxup espn , he said \" it 's not even close -- xxmaj chicago will xxunk win the xxmaj norris xxmaj division in the xxmaj playoffs , no other team is close . \" xxmaj everyone is picking xxmaj chicago ! i do n't get it , he says it 's an \" easy choice \" ? xxmaj god , xxmaj chicago was 1 - 4 - 1 against the xxmaj wings , and they won the division by a point or two , followed closely by xxmaj toronto , who is also a good team ! xxmaj as for the xxmaj leafs beating xxmaj detroit -- doubt it , but even if they do , they are n't going to get by xxmaj chicago . xxmaj if ( even more xxunk ) they get past the xxmaj hawks , they would probably face xxmaj vancouver , and lose . xxmaj as for xxmaj the xxmaj habs reaching the xxmaj finals , forget it . xxmaj even i , as a devoted xxmaj wings fan , will watch the xxmaj penguins easily three - xxunk as xxmaj cup winners . xxmaj lemieux , xxmaj jagr , xxmaj tocchet , xxmaj stevens , and xxmaj barrasso , its a done deal . xxmaj sorry xxmaj detroit , wait xxunk next year . xxmaj but hey , these were xxmaj paul 's picks , and everyone has a right to their own xxunk , but the xxmaj leafs to the xxmaj finals ? ? ? xxmaj yeah . xxmaj if they make it there , i 'll walk to xxmaj toronto to get some tickets , and that 's a 700 mile walk ! xxunk,xxbos xxmaj the idea is to clip one polygon using another polygon ( not necessarily rectangular ) as a window . xxmaj my problem then is in finding out all the new vertices of the resulting \" xxunk \" from the first one . xxmaj is this simply a matter of extending the usual algorithm whereby each of the edges of one polygon is checked against another polygon ? ? ? xxmaj is there a simpler way ? ? xxmaj comments welcome .,xxbos i 'm in xxmaj edmonton , and while that 's usually ( or at least xxup often ) the case , here we were \" xxunk \" to the actual xxup abc xxunk of the xxmaj kings / xxmaj flames game . i 'm with whoever said it earlier - xxmaj don xxmaj xxunk ( er , xxmaj whitman ) is a poor commentator , and not just for hockey . xxmaj normally , if the xxmaj oilers were still playing ( xxunk ) , i would turn off the sound and listen to the radio broadcast to get decent play - by - play announcing .,xxbos xxmaj you know , you 're absolutely right . i think we should round up all those players of xxmaj european xxunk and ship 'em back to where they came from . xxmaj let 's see , with whom should we start ? i dunno , xxmaj lemieux ? xxmaj hmmm ... sounds like he has * xxmaj french * blood in him ! ! ! xxmaj hey ! xxmaj france is part of xxmaj europe ! xxmaj send that xxmaj xxunk - xxunk boy back ! ! ! xxmaj sheesh . i do n't think it would be hard to find some xxmaj native xxmaj americans ( or xxmaj native xxmaj canadians , for that matter ) who would xxunk your claim to this great continent of * xxunk . * xxmaj ya see , if you believe the xxunk , we 're * all * xxunk of some sort . xxmaj if you really do n't think that xxmaj mogilny , xxmaj bure , xxmaj selanne , et al have improved the xxup nhl , then i 'm not sure you understand the game .\n",
              "y: CategoryList\n",
              "10,10,1,10,10\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (474 items)\n",
              "x: TextList\n",
              "xxbos - > i am looking for source - code for the radiosity - method . i do n't know what kind of machine you want it for , but the program xxmaj radiance comes with ' c ' source code - i do n't have ftp access so i could n't tell you where to get it via that way .,xxbos i am interested in any information on xxunk imaging on a sun workstation . xxmaj for the most part , i need to know if there is any hardware available to interface the system and whether the xxunk rates are sufficient to produce quality image xxunk . xxmaj any information about the subject would be greatly appreciated .,xxbos xxmaj does anyone have the xxup nhl xxup standings for xxmaj march xxunk ? i need them xxup xxunk for a project . xxmaj please post or email . xxup thanks .,xxbos a little xxunk xxmaj basic xxmaj mike 's info : xxmaj for xxmaj xxunk 's xxunk on xxup abc , these are the announcing xxunk : xxmaj devils / xxmaj isles at xxmaj pittsburgh - xxmaj gary xxmaj xxunk - by - xxunk xxmaj xxunk ) and xxmaj al xxmaj xxunk xxunk the xxunk outside the xxunk xxunk . xxmaj this xxunk will primarily seen on the xxmaj east xxmaj coast . xxmaj st . xxmaj louis at xxmaj chicago - xxmaj mike xxmaj xxunk - by xxunk xxmaj xxunk ) and xxmaj tom xxmaj xxunk xxunk the xxunk . xxmaj this xxunk will primarily be seen in the xxmaj midwest and parts of the xxmaj south . xxup la at xxmaj calgary - xxmaj al \" xxmaj do xxmaj you xxmaj believe in xxmaj xxunk ? \" xxmaj xxunk by play ) , xxmaj john xxmaj xxunk ) and xxmaj mark xxmaj jones as a xxunk reporter . xxmaj this xxunk will be seen in the xxmaj western xxup usa . xxmaj montreal 's xxunk , xxmaj xxunk xxmaj xxunk will be xxunk in the studio . xxup abc will do \" xxmaj up and xxmaj close and xxmaj personal \" with xxmaj mario during xxmaj saturday 's xxmaj wide xxmaj world of xxunk ) . xxmaj sunday will be the first xxup nhl playoff or regular network xxunk in 13 years ... not counting those silly xxmaj all - xxmaj star games on xxup xxunk for the last few years ... xxmaj for xxmaj sunday 's games , xxup abc will use 8 xxunk behind on the xxunk - super - xxunk - xxunk , close - xxunk of player 's faces at face - xxunk . xxup espn / xxup abc will not be able to use its new favorite xxunk , the ice - level shot , in xxmaj pittsburgh where too many seats would have to removed to xxunk it ... xxmaj in case of a blowout in xxunk in xxmaj pittsburgh , xxup abc will switch to xxmaj chicago game but will come back to the xxmaj pittsburgh game for updates or if the game gets xxunk ! ) .. xxup abc xxunk huge xxunk hockey standards ) since all 3 xxmaj top xxup us xxup tv - markets are involved - xxup ny xxunk xxunk xxmaj islanders / xxup nj xxunk ) , and xxunk ) . xxmaj stay tuned , xxmaj thanks xxmaj mike ,,xxbos 1993 xxmaj world xxmaj championships in xxmaj germany : xxrep 36 = xxmaj group a results : xxup sweden - xxup canada 1 - 4 ( 0 - xxunk - xxunk - 3 ) 1st : 2nd : xxup can 0 - 1 xxmaj geoff xxmaj sanderson ( xxmaj kevin xxmaj dineen ) xxunk xxup xxunk 1 - 1 xxmaj patrik xxmaj xxunk ( xxmaj jan xxmaj xxunk ) xxunk ( pp ) 3rd : xxup can 1 - 2 xxmaj geoff xxmaj sanderson xxunk ( ps ) xxup can 1 - 3 xxmaj mike xxmaj gartner ( xxmaj greg xxmaj xxunk , xxmaj xxunk xxmaj graves ) 10:44 xxup can 1 - 4 xxmaj rod brind'amour ( xxmaj xxunk xxmaj corson ) 19:59 xxmaj shots on goal : xxmaj penalties : xxmaj attendance : xxmaj referee : xxmaj sweden 10 15 12 - 37 4 * xxunk xxunk xxmaj rob xxmaj xxunk ( xxup usa ) xxmaj canada 10 13 6 - 29 6 * xxunk xxmaj bill xxmaj ranford stopped 36 shots to lead xxmaj canada to a 4 - 1 victory in a very well played game . xxmaj the first period started with a give away from a xxmaj canadian defenseman and xxmaj xxunk came in alone on xxmaj ranford but could n't put the puck over a xxunk xxmaj ranford . xxmaj later on , xxmaj kevin xxmaj dineen had a great opportunity but xxmaj soderstrom played very well too . xxmaj xxunk xxmaj nilsson had a couple of great xxunk and set up xxmaj jan xxmaj xxunk but again xxmaj ranford came up big . xxmaj period ended xxunk but the edge to xxmaj sweden in creating more opportunities . xxmaj second period action saw xxmaj tommy xxmaj soderstrom making a xxup great save . xxmaj mark xxmaj recchi made a xxunk cross ice pass to xxmaj lindros , xxmaj eric one xxunk the puck but xxmaj soderstrom was there to make a glove hand save . xxmaj at the xxunk mark , xxmaj canada started applying pressure on the xxmaj xxunk . xxmaj sanderson - xxmaj dineen - brind'amour worked hard and kept the puck in the xxmaj xxunk ' zone . xxmaj dineen gave the puck to xxmaj sanderson who skated around a xxunk xxmaj swedish defenseman , came in on xxmaj soderstrom and made a wrist shot that went it by xxmaj soderstrom 's far post , 1 - 0 xxmaj canada . xxmaj the xxmaj xxunk picked up their game after that , and xxmaj peter xxmaj xxunk had a shot that hit xxmaj ranford 's post ( the inside ) , went parallel to the goal line and out . xxmaj then xxmaj gartner got a penalty and the xxmaj xxunk a power play . xxmaj jan xxmaj xxunk took a shot from the slot , xxmaj ranford gave a rebound to xxmaj xxunk who saw xxmaj xxunk by the far post , passed the puck and xxmaj ranford was beat , 1 - 1 . xxmaj third period started as the other periods , xxmaj xxunk having most of the pressure but the xxmaj canadians always xxunk once they were close to the xxmaj xxunk goal . xxmaj at xxunk , xxmaj canada created some great chances and xxmaj xxunk xxmaj xxunk was forced to cover the puck in the xxmaj xxunk goal crease since xxmaj soderstrom lost sight of it . xxmaj that xxunk in a penalty shot , since a defenseman ca n't cover the puck in the goal crease . xxmaj geoff xxmaj sanderson took the penalty shot ( his first ever , he explained xxunk ) , and he put it low on xxmaj soderstrom 's stick side , close to the post . xxmaj excellent penalty shot to give xxmaj canada a go ahead goal . xxmaj canada increased the lead on a very suspect xxunk , xxmaj gartner xxunk a bouncing puck past xxmaj soderstrom to make it 3 - 1 . xxmaj the xxmaj xxunk xxunk out of gas then and could n't produce as good scoring chances as they had for xxunk periods . xxmaj the 4 - 1 goal came with only 1 second left , xxmaj rod brind'amour scoring on a rebound from xxmaj soderstrom , where the xxmaj swedish defense already had their xxunk in the xxunk room . a very good game ( the best in the xxup wc so far ? ) , with both goalies playing great . xxmaj soderstrom best player in xxmaj sweden , but xxmaj ranford even played better than xxmaj soderstrom , that tells you something about xxmaj ranford . xxmaj probably the best goalie in the world , were some comments after the game . xxmaj canada played a very disciplined defense , xxmaj ranford pointed out that it is easy to play well with a good defense . xxmaj lindros played a xxup lot and played well , xxmaj sanderson xxunk game xxunk with two goals . xxmaj the xxmaj xxunk - xxmaj naslund - xxmaj xxunk line xxmaj sweden 's best along with xxmaj xxunk - xxmaj xxunk xxmaj nilsson . xxmaj swedish defense played well , 197 xxunk 104 xxunk xxmaj peter xxmaj xxunk had the task of xxunk 192 xxunk 107 xxunk xxmaj eric xxmaj lindros , and managed this very well . xxmaj ranger defenseman xxmaj peter xxmaj andersson finally got to go to the xxup wc , and considering that he xxunk in xxmaj germany just a few hours before the game , he played very well . xxmaj swedish coach xxmaj xxunk xxmaj xxunk was xxunk after the game , xxunk because of the xxmaj xxunk xxunk to score , and xxunk because of the linesman 's mistake on the 1 - 3 goal . xxmaj lines information follows further below . - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - xxup italy - xxup switzerland 1 - 0 ( 0 - xxunk - 0,0 - 0 ) 1st : 2nd : xxup xxunk 1 - 0 xxmaj xxunk xxunk 3rd : xxmaj penalties : xxup xxunk 10 * xxunk , xxup xxunk 8 * xxunk xxmaj referee : xxmaj xxunk xxmaj xxunk , xxmaj slovakia xxmaj attendance : xxunk xxrep 79 - xxmaj group b results : xxup czech xxup republic - xxup germany 5 - 0 ( 0 - xxunk - xxunk - 0 ) 1st : 2nd : xxup xxunk 1 - 0 xxmaj xxunk xxmaj xxunk xxunk xxup xxunk 2 - 0 xxmaj jiri xxmaj xxunk xxunk xxup xxunk 3 - 0 xxmaj petr xxmaj xxunk xxunk 3rd : xxup xxunk 4 - 0 xxmaj xxunk xxmaj xxunk xxunk xxup xxunk 5 - 0 xxmaj xxunk xxmaj beranek xxunk xxmaj penalties : xxup xxunk 7 * xxunk , xxup xxunk 6 * xxunk 1 * xxunk 1 * xxunk game penalty xxmaj referee : xxmaj xxunk xxmaj xxunk , xxmaj canada xxmaj attendance : xxunk xxmaj the xxmaj xxunk were clearly better than the xxmaj xxunk , and the xxmaj german crowd showed their xxunk by throwing in stuff on the ice after a while . - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - xxup finland - xxup usa 1 - 1 ( 0 - xxunk - 0,0 - 1 ) 1st : 2nd : xxup xxunk 1 - 0 xxmaj xxunk xxmaj xxunk xxunk 3rd : xxup usa 1 - 1 xxmaj ed xxmaj olczyk xxunk xxmaj penalties : xxup xxunk 7 * xxunk , xxup usa 6 * xxunk xxmaj referee : xxmaj xxunk xxmaj xxunk , xxmaj russia xxmaj attendance : xxunk i hope some xxmaj xxunk can provide information from this game ( i did n't see the whole game ) . xxmaj the xxmaj xxunk took the lead on a xxmaj xxunk xxmaj xxunk slap shot from the blue line , and a soft goal for an xxunk xxmaj mike xxmaj richter . xxmaj as far as the play in the second period goes , the xxmaj xxunk seemed to have the most control , so a 1 - 0 lead was warranted as i saw it . xxrep 79 - xxup sweden xxup canada xxmaj goaltender : 30 xxmaj tommy xxmaj soderstrom 30 xxmaj bill xxmaj ranford xxmaj defense : 8 xxmaj kenneth xxmaj xxunk 5 xxmaj norm xxmaj maciver 14 xxmaj fredrik xxmaj xxunk 24 xxmaj dave xxmaj manson 3 xxmaj peter xxmaj xxunk 25 xxmaj geoff xxmaj smith 55 xxmaj peter xxmaj andersson 19 xxmaj brian xxmaj benning 7 xxmaj xxunk xxmaj xxunk 6 xxmaj terry xxmaj carkner 28 xxmaj roger xxmaj xxunk 3 xxmaj garry xxmaj galley 4 xxmaj xxunk xxmaj xxunk xxmaj forwards : 29 xxmaj mikael xxmaj xxunk 15 xxmaj dave xxmaj gagner 9 xxmaj thomas xxmaj xxunk 27 xxmaj xxunk xxmaj graves 34 xxmaj mikael xxmaj andersson 22 xxmaj mike xxmaj gartner 19 xxmaj markus xxmaj naslund 20 xxmaj paul xxmaj kariya 21 xxmaj peter xxmaj xxunk 88 xxmaj eric xxmaj lindros 18 xxmaj jonas xxmaj xxunk 8 xxmaj mark xxmaj recchi 5 xxmaj patrik xxmaj xxunk 17 xxmaj rod brind'amour 20 xxmaj jan xxmaj xxunk 9 xxmaj xxunk xxmaj corson 4 xxmaj xxunk xxmaj nilsson 11 xxmaj kevin xxmaj dineen 22 xxmaj xxunk xxmaj xxunk 10 xxmaj geoff xxmaj sanderson 26 xxmaj michael xxmaj nylander 12 xxmaj greg xxmaj xxunk ( 34 xxmaj andersson / 18 xxmaj xxunk ) 14 xxmaj brian xxmaj xxunk 16 xxmaj kelly xxmaj buchberger\n",
              "y: CategoryList\n",
              "1,1,10,10,10\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(7504, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(7504, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7ffb1f950a70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: ...\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(7504, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(7504, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "id": "Ji0DhE9muZ6U",
        "outputId": "e0211d07-93e6-4737-e0f0-aed1c7500392"
      },
      "source": [
        "#fitting again\n",
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.330860</td>\n",
              "      <td>0.244025</td>\n",
              "      <td>0.928270</td>\n",
              "      <td>00:20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "qbxUZOJIuyeT",
        "outputId": "a2c7b50f-4795-41b9-d884-1b16c16d06c4"
      },
      "source": [
        "#get the predictions from validation set and show in crosstab to check correctness\n",
        "preds, targets = learn.get_preds()\n",
        "predictions = np.argmax(preds, axis=1)\n",
        "pd.crosstab(predictions, targets)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>225</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0    0    1\n",
              "row_0          \n",
              "0      225   25\n",
              "1        9  215"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0bvStvrwOOT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}